{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple Stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "We are going to use Apple's stock price.\n",
    "\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/02 18:51:02 WARN Utils: Your hostname, Ana-Matebook resolves to a loopback address: 127.0.1.1; using 192.168.1.137 instead (on interface wlp2s0)\n",
      "23/02/02 18:51:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/02 18:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"exercise9-timeseries\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/09_Time_Series/Apple_Stock/appl_1980_2014.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Assign it to a variable apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apple_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"appl_1980_2014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+---------+---------+\n",
      "|               Date| Open| High|  Low|Close|   Volume|Adj Close|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+\n",
      "|2014-07-08 00:00:00|96.27| 96.8|93.92|95.35| 65130000|    95.35|\n",
      "|2014-07-07 00:00:00|94.14|95.99| 94.1|95.97| 56305400|    95.97|\n",
      "|2014-07-03 00:00:00|93.67| 94.1| 93.2|94.03| 22891800|    94.03|\n",
      "|2014-07-02 00:00:00|93.87|94.06|93.09|93.48| 28420900|    93.48|\n",
      "|2014-07-01 00:00:00|93.52|94.07|93.13|93.52| 38170200|    93.52|\n",
      "|2014-06-30 00:00:00| 92.1|93.73|92.09|92.93| 49482300|    92.93|\n",
      "|2014-06-27 00:00:00|90.82| 92.0|90.77|91.98| 64006800|    91.98|\n",
      "|2014-06-26 00:00:00|90.37|91.05| 89.8| 90.9| 32595800|     90.9|\n",
      "|2014-06-25 00:00:00|90.21| 90.7|89.65|90.36| 36852200|    90.36|\n",
      "|2014-06-24 00:00:00|90.75|91.74|90.19|90.28| 38988300|    90.28|\n",
      "|2014-06-23 00:00:00|91.32|91.62| 90.6|90.83| 43618200|    90.83|\n",
      "|2014-06-20 00:00:00|91.85|92.55| 90.9|90.91|100813200|    90.91|\n",
      "|2014-06-19 00:00:00|92.29| 92.3|91.34|91.86| 35486400|    91.86|\n",
      "|2014-06-18 00:00:00|92.27|92.29|91.35|92.18| 33493800|    92.18|\n",
      "|2014-06-17 00:00:00|92.31| 92.7| 91.8|92.08| 29689800|    92.08|\n",
      "|2014-06-16 00:00:00|91.51|92.75|91.45| 92.2| 35561000|     92.2|\n",
      "|2014-06-13 00:00:00| 92.2|92.44|90.88|91.28| 54525000|    91.28|\n",
      "|2014-06-12 00:00:00|94.04|94.12| 91.9|92.29| 54749000|    92.29|\n",
      "|2014-06-11 00:00:00|94.13|94.76|93.47|93.86| 45681000|    93.86|\n",
      "|2014-06-10 00:00:00|94.73|95.05|93.57|94.25| 62777000|    94.25|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.  Check out the type of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Transform the Date column as a datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- as_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It is already a date column but converting it here again:\n",
    "apple_df = apple_df.withColumn(\"as_date\", func.to_date(func.col(\"Date\"),\"MM-dd-yyyy\"))\n",
    "apple_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6.  Set the date as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.  Is there any duplicate dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8465"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_df.select(\"as_date\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_df.select(\"as_date\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def has_duplicates(df: DataFrame, column_name: str) -> bool:\n",
    "    unique_values = df.select(column_name).distinct().count()\n",
    "    all_values = df.select(column_name).count()\n",
    "    return all_values > unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_duplicates(apple_df, \"as_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8.  Ops...it seems the index is from the most recent date. Make the first entry the oldest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+--------+---------+----------+\n",
      "|               Date| Open| High|  Low|Close|  Volume|Adj Close|   as_date|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+----------+\n",
      "|2014-07-08 00:00:00|96.27| 96.8|93.92|95.35|65130000|    95.35|2014-07-08|\n",
      "|2014-07-07 00:00:00|94.14|95.99| 94.1|95.97|56305400|    95.97|2014-07-07|\n",
      "|2014-07-03 00:00:00|93.67| 94.1| 93.2|94.03|22891800|    94.03|2014-07-03|\n",
      "|2014-07-02 00:00:00|93.87|94.06|93.09|93.48|28420900|    93.48|2014-07-02|\n",
      "|2014-07-01 00:00:00|93.52|94.07|93.13|93.52|38170200|    93.52|2014-07-01|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_df = apple_df.sort(\"as_date\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+\n",
      "|               Date| Open| High|  Low|Close|   Volume|Adj Close|   as_date|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+\n",
      "|1980-12-12 00:00:00|28.75|28.87|28.75|28.75|117258400|     0.45|1980-12-12|\n",
      "|1980-12-15 00:00:00|27.38|27.38|27.25|27.25| 43971200|     0.42|1980-12-15|\n",
      "|1980-12-16 00:00:00|25.37|25.37|25.25|25.25| 26432000|     0.39|1980-12-16|\n",
      "|1980-12-17 00:00:00|25.87| 26.0|25.87|25.87| 21610400|      0.4|1980-12-17|\n",
      "|1980-12-18 00:00:00|26.63|26.75|26.63|26.63| 18362400|     0.41|1980-12-18|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Get the last business day of each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "apple_df = apple_df.withColumn(\"day\", func.dayofmonth(\"as_date\"))\n",
    "apple_df = apple_df.withColumn(\"month\", func.month(\"as_date\"))\n",
    "apple_df = apple_df.withColumn(\"year\", func.year(\"as_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "|               Date| Open| High|  Low|Close|   Volume|Adj Close|   as_date|day|month|year|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "|1980-12-12 00:00:00|28.75|28.87|28.75|28.75|117258400|     0.45|1980-12-12| 12|   12|1980|\n",
      "|1980-12-15 00:00:00|27.38|27.38|27.25|27.25| 43971200|     0.42|1980-12-15| 15|   12|1980|\n",
      "|1980-12-16 00:00:00|25.37|25.37|25.25|25.25| 26432000|     0.39|1980-12-16| 16|   12|1980|\n",
      "|1980-12-17 00:00:00|25.87| 26.0|25.87|25.87| 21610400|      0.4|1980-12-17| 17|   12|1980|\n",
      "|1980-12-18 00:00:00|26.63|26.75|26.63|26.63| 18362400|     0.41|1980-12-18| 18|   12|1980|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------------------+------+------+------+------+---------+---------+----------+----+\n",
      "|month|day|               Date|  Open|  High|   Low| Close|   Volume|Adj Close|   as_date|year|\n",
      "+-----+---+-------------------+------+------+------+------+---------+---------+----------+----+\n",
      "|    6| 30|2014-06-30 00:00:00|  92.1| 93.73| 92.09| 92.93| 49482300|    92.93|2014-06-30|2014|\n",
      "|    4| 30|2014-04-30 00:00:00|592.64|599.43| 589.8|590.09|114160200|    83.83|2014-04-30|2014|\n",
      "|    3| 31|2014-03-31 00:00:00|539.23|540.81|535.93|536.74| 42167300|    76.25|2014-03-31|2014|\n",
      "|    1| 31|2014-01-31 00:00:00|495.18|501.53|493.55| 500.6|116199300|    70.69|2014-01-31|2014|\n",
      "|   12| 31|2013-12-31 00:00:00|554.17|561.28| 554.0|561.02| 55771100|    79.23|2013-12-31|2013|\n",
      "|   10| 31|2013-10-31 00:00:00| 525.0|527.49|521.27| 522.7| 68924100|    73.39|2013-10-31|2013|\n",
      "|    9| 30|2013-09-30 00:00:00|477.25|481.66|474.41|476.75| 65039100|    66.94|2013-09-30|2013|\n",
      "|    7| 31|2013-07-31 00:00:00|454.99|457.34|449.43|452.53| 80739400|    63.12|2013-07-31|2013|\n",
      "|    5| 31|2013-05-31 00:00:00| 452.5| 457.1| 449.5|449.73| 96075700|    62.73|2013-05-31|2013|\n",
      "|    4| 30|2013-04-30 00:00:00| 435.1|445.25|432.07|442.78|172884600|    61.35|2013-04-30|2013|\n",
      "|    1| 31|2013-01-31 00:00:00|456.98|459.28|454.98|455.49| 79833600|    62.75|2013-01-31|2013|\n",
      "|   12| 31|2012-12-31 00:00:00|510.53| 535.4| 509.0|532.17|164873100|    73.31|2012-12-31|2012|\n",
      "|   11| 30|2012-11-30 00:00:00|586.79| 588.4|582.68|585.28| 97829900|    80.63|2012-11-30|2012|\n",
      "|   10| 31|2012-10-31 00:00:00|594.88|601.96| 587.7|595.32|127500800|    81.64|2012-10-31|2012|\n",
      "|    8| 31|2012-08-31 00:00:00|667.25| 668.6|657.25|665.24| 84580300|    91.23|2012-08-31|2012|\n",
      "|    7| 31|2012-07-31 00:00:00|603.23| 611.7|602.72|610.76|115581900|     83.4|2012-07-31|2012|\n",
      "|    5| 31|2012-05-31 00:00:00|580.74| 581.5|571.46|577.73|122918600|    78.89|2012-05-31|2012|\n",
      "|    4| 30|2012-04-30 00:00:00| 597.8| 598.4| 583.0|583.98|126536200|    79.74|2012-04-30|2012|\n",
      "|    2| 29|2012-02-29 00:00:00|541.56|547.61| 535.7|542.44|238002800|    74.07|2012-02-29|2012|\n",
      "|    1| 31|2012-01-31 00:00:00|455.59|458.24|453.07|456.48| 97920900|    62.33|2012-01-31|2012|\n",
      "+-----+---+-------------------+------+------+------+------+---------+---------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_days = apple_df.groupBy(\"month\").agg(func.max(\"day\").alias(\"day\"))\n",
    "max_apple_df = apple_df.join(max_days, on=[\"month\", \"day\"])\n",
    "max_apple_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10.  What is the difference in days between the first day and the oldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|  max_date|  min_date|\n",
      "+----------+----------+\n",
      "|2014-07-08|1980-12-12|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxmin_apple_df = apple_df.agg(func.max(\"as_date\").alias(\"max_date\"), func.min(\"as_date\").alias(\"min_date\"))\n",
    "maxmin_apple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+\n",
      "|  max_date|  min_date|                diff|\n",
      "+----------+----------+--------------------+\n",
      "|2014-07-08|1980-12-12|INTERVAL '12261' DAY|\n",
      "+----------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_apple_df = maxmin_apple_df.withColumn(\"diff\", maxmin_apple_df.max_date - maxmin_apple_df.min_date)\n",
    "diff_apple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- max_date: date (nullable = true)\n",
      " |-- min_date: date (nullable = true)\n",
      " |-- diff: interval day (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_apple_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| diff|\n",
      "+-----+\n",
      "|12261|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Another way\n",
    "diff_apple_df_2 = maxmin_apple_df.select(func.datediff(maxmin_apple_df.max_date, maxmin_apple_df.min_date).alias('diff'))\n",
    "diff_apple_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- diff: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "diff_apple_df_2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11.  How many months in the data we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "|               Date| Open| High|  Low|Close|   Volume|Adj Close|   as_date|day|month|year|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "|1980-12-12 00:00:00|28.75|28.87|28.75|28.75|117258400|     0.45|1980-12-12| 12|   12|1980|\n",
      "|1980-12-15 00:00:00|27.38|27.38|27.25|27.25| 43971200|     0.42|1980-12-15| 15|   12|1980|\n",
      "|1980-12-16 00:00:00|25.37|25.37|25.25|25.25| 26432000|     0.39|1980-12-16| 16|   12|1980|\n",
      "|1980-12-17 00:00:00|25.87| 26.0|25.87|25.87| 21610400|      0.4|1980-12-17| 17|   12|1980|\n",
      "|1980-12-18 00:00:00|26.63|26.75|26.63|26.63| 18362400|     0.41|1980-12-18| 18|   12|1980|\n",
      "|1980-12-19 00:00:00|28.25|28.38|28.25|28.25| 12157600|     0.44|1980-12-19| 19|   12|1980|\n",
      "|1980-12-22 00:00:00|29.63|29.75|29.63|29.63|  9340800|     0.46|1980-12-22| 22|   12|1980|\n",
      "|1980-12-23 00:00:00|30.88| 31.0|30.88|30.88| 11737600|     0.48|1980-12-23| 23|   12|1980|\n",
      "|1980-12-24 00:00:00| 32.5|32.63| 32.5| 32.5| 12000800|     0.51|1980-12-24| 24|   12|1980|\n",
      "|1980-12-26 00:00:00| 35.5|35.62| 35.5| 35.5| 13893600|     0.55|1980-12-26| 26|   12|1980|\n",
      "|1980-12-29 00:00:00| 36.0|36.13| 36.0| 36.0| 23290400|     0.56|1980-12-29| 29|   12|1980|\n",
      "|1980-12-30 00:00:00|35.25|35.25|35.12|35.12| 17220000|     0.55|1980-12-30| 30|   12|1980|\n",
      "|1980-12-31 00:00:00|34.25|34.25|34.13|34.13|  8937600|     0.53|1980-12-31| 31|   12|1980|\n",
      "|1981-01-02 00:00:00| 34.5|34.75| 34.5| 34.5|  5415200|     0.54|1981-01-02|  2|    1|1981|\n",
      "|1981-01-05 00:00:00|33.87|33.87|33.75|33.75|  8932000|     0.53|1981-01-05|  5|    1|1981|\n",
      "|1981-01-06 00:00:00|32.37|32.37|32.25|32.25| 11289600|      0.5|1981-01-06|  6|    1|1981|\n",
      "|1981-01-07 00:00:00| 31.0| 31.0|30.88|30.88| 13921600|     0.48|1981-01-07|  7|    1|1981|\n",
      "|1981-01-08 00:00:00|30.37|30.37|30.25|30.25|  9956800|     0.47|1981-01-08|  8|    1|1981|\n",
      "|1981-01-09 00:00:00|31.88| 32.0|31.88|31.88|  5376000|      0.5|1981-01-09|  9|    1|1981|\n",
      "|1981-01-12 00:00:00|31.88|31.88|31.62|31.62|  5924800|     0.49|1981-01-12| 12|    1|1981|\n",
      "+-------------------+-----+-----+-----+-----+---------+---------+----------+---+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "|  363|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_df.agg(func.count_distinct(apple_df.month, apple_df.day).alias('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. Plot the 'Adj Close' value. Set the size of the figure to 13.5 x 9 inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Create your own question and answer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pyspark_exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "47f8ae1dea83c3e576b0e025c42e92cd56d6b031af03aabe8f1f34ede64efee8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
